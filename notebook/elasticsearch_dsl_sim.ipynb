{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075dbcf0",
   "metadata": {},
   "source": [
    "# MoreLikeThis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f274767",
   "metadata": {},
   "source": [
    "`Elasticsearch` 中的 `More Like This （MLT）`是一种基于文本相似度的检索方法，它可以根据指定的文档或文本，查找与之相似的其他文档。More Like This 查询可以帮助用户发现与其感兴趣的内容类似的其他内容，从而提高搜索的精度和个性化。\n",
    "\n",
    "`More Like This` 查询可以在 `Elasticsearch` 中使用，它的实现基于 Elasticsearch 的 Lucene 搜索引擎库。该查询需要指定要匹配的文档 ID 或文本内容，然后 Elasticsearch 会基于这个文档的词项生成一个查询，然后在索引中查找与查询相似的文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdbdf7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:59:53.745822Z",
     "start_time": "2023-07-02T09:59:53.506606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost'}])>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch_dsl import Document, Text, Keyword, Index, connections\n",
    "from elasticsearch_dsl.query import MoreLikeThis\n",
    "\n",
    "# 连接到Elasticsearch\n",
    "connections.create_connection(hosts=['localhost'], timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da37f289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T10:00:07.419619Z",
     "start_time": "2023-07-02T10:00:06.547936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'created'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建索引并设置 mapping\n",
    "index_name = 'index_cos'\n",
    "index = Index(index_name)\n",
    "\n",
    "if index.exists():\n",
    "    index.delete()\n",
    "\n",
    "index.settings(number_of_shards=1, number_of_replicas=0)\n",
    "\n",
    "@index.document\n",
    "class CosDocument(Document):\n",
    "    title = Text(analyzer='snowball')\n",
    "    body = Text(analyzer='snowball')\n",
    "    \n",
    "    class Index:\n",
    "        name = index_name\n",
    "    \n",
    "# 向索引中添加数据\n",
    "doc1 = CosDocument(title='Python programming', body='Python is a popular programming language.')\n",
    "doc1.save()\n",
    "doc2 = CosDocument(title='Java programming', body='Java is a widely used programming language.')\n",
    "doc2.save()\n",
    "doc3 = CosDocument(title='Java programming', body='I want a book.')\n",
    "doc3.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b8bd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T10:09:50.943471Z",
     "start_time": "2023-07-02T10:09:50.933462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with doc1: 1.5415431\n",
      "Similarity with doc1: 0.28532696\n"
     ]
    }
   ],
   "source": [
    "# 计算相似度\n",
    "query = MoreLikeThis(\n",
    "    fields=['title', 'body'],\n",
    "    like={'_id': doc1.meta.id},\n",
    "    min_term_freq=1,    # 一篇文档中一个词语至少出现次数，小于这个值的词将被忽略，\n",
    "    min_doc_freq=1,     # 一个词语最少在多少篇文档中出现，小于这个值的词会将被忽略\n",
    "    max_query_terms=12  # 一条查询语句中允许最多查询词语的个数\n",
    ")\n",
    "search = CosDocument.search().query(query)\n",
    "response = search.execute()\n",
    "for hit in response:\n",
    "    print('Similarity with doc1:', hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d84fc",
   "metadata": {},
   "source": [
    "- percent_terms_to_match：匹配项（term）的百分比，默认是0.3\n",
    "- min_term_freq：一篇文档中一个词语至少出现次数，小于这个值的词将被忽略，默认是2\n",
    "- max_query_terms：一条查询语句中允许最多查询词语的个数，默认是25\n",
    "- stop_words：设置停止词，匹配时会忽略停止词\n",
    "- min_doc_freq：一个词语最少在多少篇文档中出现，小于这个值的词会将被忽略，默认是无限制\n",
    "- max_doc_freq：一个词语最多在多少篇文档中出现，大于这个值的词会将被忽略，默认是无限制\n",
    "- min_word_len：最小的词语长度，默认是0\n",
    "- max_word_len：最多的词语长度，默认无限制\n",
    "- boost_terms：设置词语权重，默认是1\n",
    "- boost：设置查询权重，默认是1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289577d7",
   "metadata": {},
   "source": [
    "在上面的示例中，\n",
    "\n",
    "1. 我们首先创建了一个`elasticsearch`的连接，\n",
    "1. 然后使用elasticsearch_dsl创建了一个名为`index_cos`的索引，并定义了一个名为CosDocument的文档类型，其中包含了两个字段：title和body。\n",
    "1. 接着，我们向索引中添加了几个文档，分别表示Python编程和Java编程。\n",
    "1. 最后，我们使用MoreLikeThis查询计算了与doc1（表示Python编程）相似的文档，并打印出了它们的相似度分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef4232",
   "metadata": {},
   "source": [
    "> Snowball\n",
    "\n",
    "Snowball（也称为Porter2）是一种流行的词干提取算法，用于将单词转换为它们的基本形式，以便它们可以更容易地与其他单词进行比较和分析。Snowball是Martin Porter开发的算法，它是Porter词干提取算法的改进版本。Snowball算法可以用于各种语言，包括英语、法语、德语、荷兰语、意大利语、葡萄牙语、西班牙语、瑞典语、挪威语、丹麦语、芬兰语、俄语、土耳其语等。\n",
    "\n",
    "Snowball算法的基本思想是将单词转换为它们的基本形式，而不是仅仅削减词尾。例如，对于单词“running”，Snowball算法将其转换为“run”，而不是仅仅删除词尾“ing”。\n",
    "\n",
    "Snowball算法的工作原理是将单词分解为一系列规则，然后应用这些规则以将单词转换为其基本形式。这些规则通常包括删除词尾、删除前缀、对元音字母进行转换等。Snowball算法还可以根据不同的语言和应用程序进行自定义配置。\n",
    "\n",
    "在搜索引擎和信息检索中，Snowball算法通常用于对搜索查询进行处理，以便将查询中的单词转换为其基本形式，并与文档中的单词进行匹配。这样可以增加搜索的准确性和召回率，提高搜索结果的质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0e5ac",
   "metadata": {},
   "source": [
    "# Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45512823",
   "metadata": {},
   "source": [
    "> 使用`elasticsearch_dsl`存储向量数据并计算余弦相似度\n",
    "\n",
    "使用`Elasticsearch`的`Vector`数据类型和`Vector Similarity`函数。下面是一个使用`elasticsearch_dsl`存储向量数据并计算余弦相似度的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70196f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T10:10:47.996178Z",
     "start_time": "2023-07-02T10:10:47.163073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'created'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from elasticsearch_dsl import Search, Document, Index, connections, DenseVector\n",
    "from elasticsearch_dsl.query import ScriptScore, Q, MatchAll\n",
    "\n",
    "# 连接到Elasticsearch\n",
    "connections.create_connection(hosts=['localhost'], timeout=20)\n",
    "\n",
    "# 创建索引并设置mapping，指定字段类型为DenseVector\n",
    "dims = 50\n",
    "index_name = 'index_vec'\n",
    "index = Index(index_name)\n",
    "\n",
    "if index.exists():\n",
    "    index.delete()\n",
    "\n",
    "@index.document\n",
    "class VecDocument(Document):\n",
    "    vector = DenseVector(dims=50)\n",
    "    \n",
    "    class Index:\n",
    "        name = index_name\n",
    "\n",
    "VecDocument.init()\n",
    "# 向索引中添加向量数据\n",
    "doc1 = VecDocument(meta={'id': '1'}, vector=np.random.random(dims).tolist())\n",
    "doc1.save()\n",
    "doc2 = VecDocument(meta={'id': '2'}, vector=np.random.random(dims).tolist())\n",
    "doc2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fbc127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T10:12:51.419736Z",
     "start_time": "2023-07-02T10:12:51.408726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity with query vector: 1.7647238\n",
      "Cosine similarity with query vector: 1.728144\n"
     ]
    }
   ],
   "source": [
    "search = Search(index=index_name)\n",
    "query_vector = np.random.random(dims).tolist()\n",
    "\n",
    "# 计算余弦相似度\n",
    "script = {\n",
    "    \"source\": \"cosineSimilarity(params.query_vector, 'vector') + 1.0\",\n",
    "    \"params\": {\"query_vector\": query_vector}\n",
    "}\n",
    "query = MatchAll()\n",
    "script_score = ScriptScore(query=query, script=script)\n",
    "s = search.query(script_score)\n",
    "\n",
    "index.refresh()\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print('Cosine similarity with query vector:', hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a972c",
   "metadata": {},
   "source": [
    "1. 首先使用`elasticsearch_dsl`创建了一个名为`index_vec`的索引，定义了一个名为`VecDocument`的文档类型，其中包含了一个名为`vector`的向量字段。\n",
    "1. 接着，我们向索引中添加了两个带有向量数据的文档，分别表示两个向量。\n",
    "1. 最后，我们使用`ScriptScore`查询计算了与查询向量的余弦相似度，并打印出了它们的分数。\n",
    "\n",
    "在这个查询中，我们使用了`cosineSimilarity()`函数，它计算两个向量之间的余弦相似度，其中第一个参数是查询向量，第二个参数是文档中的向量字段。注意，`ScriptScore`函数会将所有分数加上`1.0`，以避免出现负数分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9752e",
   "metadata": {},
   "source": [
    "# 使用Transformers模型进行向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5022787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T08:28:55.296896Z",
     "start_time": "2023-06-25T08:28:48.058332Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from transformers import BertTokenizer, ErnieModel\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def vec_model(model_path):\n",
    "    \"\"\"\"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    model = ErnieModel.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "def text2vec(text, model=None, tokenizer=None, dtype='list', flatten=True):\n",
    "    \"\"\"\"\"\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    vec = output[1]\n",
    "    if flatten:\n",
    "        vec = vec.flatten()\n",
    "    if dtype == 'list':\n",
    "        vec = vec.tolist()\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a38f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T08:29:01.498439Z",
     "start_time": "2023-06-25T08:28:56.204913Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '/data/models/ernie-3.0-base-zh'\n",
    "model, tokenizer = vec_model(model_path)\n",
    "\n",
    "# 需要预测的文本\n",
    "text = \"这是一个测试文本\"\n",
    "\n",
    "text_vec = text2vec(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adedb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T08:29:02.889596Z",
     "start_time": "2023-06-25T08:29:02.868652Z"
    }
   },
   "outputs": [],
   "source": [
    "len(text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00841b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T08:29:27.567671Z",
     "start_time": "2023-06-25T08:29:27.555584Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Vec: {text_vec[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fbc1c",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
